{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required librairies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier,RandomForestClassifier \n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read both train and test datasets\n",
    "ds1=pd.read_csv('C://Users/user/Downloads/train.csv')\n",
    "ds2=pd.read_csv('C://Users/user/Downloads/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove unnecessery columns and create a lable vector from train data(ds1)\n",
    "X_train=ds1.drop(labels=['default payment next month','Unnamed: 0','ID'],axis=1)\n",
    "X_train=X_train.rename(columns={'PAY_0':'PAY_1'})\n",
    "y_train=ds1['default payment next month']\n",
    "\n",
    "X_test=ds2.drop(labels=['Unnamed: 0','ID'],axis=1)\n",
    "X_test=X_test.rename(columns={'PAY_0':'PAY_1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorie given money amount from o to 8 for every 100000 \n",
    "for dataset in [X_train,X_test]:\n",
    "    cols=['LIMIT_BAL','BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6','PAY_AMT1','PAY_AMT2','PAY_AMT3','PAY_AMT4','PAY_AMT5','PAY_AMT6']\n",
    "    for col in cols:\n",
    "        dataset.loc[(dataset[col] <= 100000),col] = 0\n",
    "        dataset.loc[(dataset[col] > 100000) & (dataset[col] <= 200000),col] = 1\n",
    "        dataset.loc[(dataset[col] > 200000) & (dataset[col] <= 300000),col] = 2\n",
    "        dataset.loc[(dataset[col] > 300000) & (dataset[col] <= 400000),col] = 3\n",
    "        dataset.loc[(dataset[col] > 400000) & (dataset[col] <= 500000),col] = 4\n",
    "        dataset.loc[(dataset[col] > 500000) & (dataset[col] <= 600000),col] = 5\n",
    "        dataset.loc[(dataset[col] > 600000) & (dataset[col] <= 700000),col] = 6\n",
    "        dataset.loc[(dataset[col] > 700000) & (dataset[col] <= 800000),col] = 7\n",
    "        dataset.loc[(dataset[col] > 800000),col] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('knn', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=-1, n_neighbors=9, p=2,\n",
       "           weights='uniform')), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, ma...=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=None, voting='hard', weights=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize RandomForestClassifier, KNeighborsClassifier, GaussianNB, DescisionTreeClassifier, Multi-Layer-Perceptron \n",
    "rf = RandomForestClassifier(criterion = \"gini\", \n",
    "                                       min_samples_leaf = 1, \n",
    "                                       min_samples_split = 10,   \n",
    "                                       n_estimators=100, \n",
    "                                       max_features='auto', \n",
    "                                       oob_score=True, \n",
    "                                       random_state=1, \n",
    "                                       n_jobs=-1)\n",
    "rf.fit(X_train,y_train)\n",
    "knn = KNeighborsClassifier(n_neighbors = 9,n_jobs=-1,weights='uniform',algorithm='auto')\n",
    "knn.fit(X_train,y_train)\n",
    "gnb = GaussianNB(priors=None, var_smoothing=1e-09)\n",
    "gnb.fit(X_train,y_train)\n",
    "dt=DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=5, min_samples_split=2, min_samples_leaf=1)\n",
    "gnb.fit(X_train,y_train)\n",
    "mlpc=MLPClassifier(hidden_layer_sizes=(25,25,25),max_iter=500)\n",
    "mlpc.fit(X_train,y_train)\n",
    "\n",
    "#initialise VotingClassifier from all above estimators\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('knn', knn), ('rf', rf), ('gnb', gnb),('dt',dt),('mlpc',mlpc)], voting='hard')\n",
    "eclf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict label values for test data from trained model\n",
    "y_pred=eclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2['Prediction']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2.to_csv('C://Users/user/Downloads/test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
